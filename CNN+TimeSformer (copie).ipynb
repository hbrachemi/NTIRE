{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTRq65Wa_egm"
   },
   "source": [
    "#Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5421,
     "status": "ok",
     "timestamp": 1677833298088,
     "user": {
      "displayName": "Hanene Fatima Zohra BRACHEMI MEFTAH",
      "userId": "05471859942716114157"
     },
     "user_tz": -60
    },
    "id": "13ZqxNPEBLXl"
   },
   "outputs": [],
   "source": [
    "from dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677833298088,
     "user": {
      "displayName": "Hanene Fatima Zohra BRACHEMI MEFTAH",
      "userId": "05471859942716114157"
     },
     "user_tz": -60
    },
    "id": "TeyqH38mAac3"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1677833298088,
     "user": {
      "displayName": "Hanene Fatima Zohra BRACHEMI MEFTAH",
      "userId": "05471859942716114157"
     },
     "user_tz": -60
    },
    "id": "AJV2AMX_eERh"
   },
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    \"\"\"Adaptive dataset.\"\"\"\n",
    "\n",
    "    def __init__(self,db_path='',ids_path='',part='',\n",
    "                 \n",
    "                 labels_path=''\n",
    "                 ):\n",
    "        self.db_path=db_path       \n",
    "        self.labels_path=labels_path\n",
    "        self.ids_path=ids_path\n",
    "        self.part=part\n",
    "        \n",
    "        pickle_in = open(self.ids_path,'rb')\n",
    "        self.list_IDs= pickle.load(pickle_in)\n",
    "        self.list_IDs=list(self.list_IDs)\n",
    "        pickle_in.close()\n",
    "        \n",
    "        pickle_in = open(self.labels_path,'rb')\n",
    "        self.labels = pickle.load(pickle_in)\n",
    "        pickle_in.close()\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(len(self.list_IDs))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        id=self.list_IDs[idx]\n",
    "        if id[0] == 'L':\n",
    "            id='l'+id[1:]\n",
    "        if id[0] == 'K':\n",
    "            id='k'+id[1:]\n",
    "\n",
    "        x=np.load(os.path.join(self.db_path,id+'.npy'))\n",
    "        x=torch.from_numpy(x)\n",
    "        x = (x.permute(2,0,1)).float()\n",
    "        print(x.shape)\n",
    "\n",
    "\n",
    "        label = self.labels[self.list_IDs[idx]]\n",
    "        if id.split(\"/\")[0] != 'train':\n",
    "          label = label * 20\n",
    "        label = np.array([label])\n",
    "        label = label.astype('float32')\n",
    "       \n",
    "        return x,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1677833298089,
     "user": {
      "displayName": "Hanene Fatima Zohra BRACHEMI MEFTAH",
      "userId": "05471859942716114157"
     },
     "user_tz": -60
    },
    "id": "o35Kfy9cDInK"
   },
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    \"\"\"Adaptive dataset.\"\"\"\n",
    "\n",
    "    def __init__(self,db_path='',ids_path='',part='',\n",
    "                 \n",
    "                 labels_path=''\n",
    "                 ):\n",
    "        self.db_path=db_path       \n",
    "        self.labels_path=labels_path\n",
    "        self.ids_path=ids_path\n",
    "        self.part=part\n",
    "        \n",
    "        pickle_in = open(self.ids_path,'rb')\n",
    "        self.list_IDs= pickle.load(pickle_in)\n",
    "        self.list_IDs=list(self.list_IDs)\n",
    "        pickle_in.close()\n",
    "        \n",
    "        pickle_in = open(self.labels_path,'rb')\n",
    "        self.labels = pickle.load(pickle_in)\n",
    "        pickle_in.close()\n",
    "        \n",
    "        ids = []\n",
    "        for id in self.list_IDs:\n",
    "            if id.split(\"/\")[0] != 'train':\n",
    "                continue\n",
    "            ids.append(id)\n",
    "        self.list_IDs = ids\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(len(self.list_IDs))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        id=self.list_IDs[idx]\n",
    "        if id[0] == 'L':\n",
    "            id='l'+id[1:]\n",
    "            \n",
    "        if id[0] == 'K':\n",
    "            id='k'+id[1:]\n",
    "\n",
    "        x=np.load(os.path.join(self.db_path,id+'.npy'))\n",
    "        x=torch.from_numpy(x)\n",
    "      # print(x.shape)\n",
    "        x = (x.permute(2,0,1)).float()\n",
    "       #x = torch.unsqueeze(x,0)\n",
    "        label = self.labels[self.list_IDs[idx]]\n",
    "       # if id.split(\"/\")[0] != 'train':\n",
    "       #     label = label * 20\n",
    "        label = np.array([label])\n",
    "        label = label.astype('float32')\n",
    "       \n",
    "        return x,label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DmzcZgS0UgYE"
   },
   "source": [
    "**TO EDIT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 459,
     "status": "ok",
     "timestamp": 1677833298543,
     "user": {
      "displayName": "Hanene Fatima Zohra BRACHEMI MEFTAH",
      "userId": "05471859942716114157"
     },
     "user_tz": -60
    },
    "id": "W1gfx3NIAmSu",
    "outputId": "55666c87-340a-4fe6-a7a2-1a5b7d74fc05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Train Data : 839\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dataset_withIDs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m train_data\u001b[38;5;241m=\u001b[39mdataset(db_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Features/resnet50/\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      2\u001b[0m                         ids_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mids.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m                         labels_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./scores1.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m                  )\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of Train Data : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m val_data\u001b[38;5;241m=\u001b[39m\u001b[43mdataset_withIDs\u001b[49m(db_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Features/resnet50/\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m                         ids_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mids.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m                         labels_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./scores1.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     11\u001b[0m                  )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of Train Data : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(val_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset_withIDs' is not defined"
     ]
    }
   ],
   "source": [
    "train_data=dataset(db_path='./Features/resnet50/',\n",
    "                        ids_path='ids.pickle',\n",
    "                        labels_path='./scores1.pickle'\n",
    "                 )\n",
    "                 \n",
    "print(f\"Length of Train Data : {len(train_data)}\")\n",
    "\n",
    "val_data=dataset_withIDs(db_path='./Features/resnet50/',\n",
    "                        ids_path='ids.pickle',\n",
    "                        labels_path='./scores1.pickle'\n",
    "                 )\n",
    "                 \n",
    "print(f\"Length of Train Data : {len(val_data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G66pU790CW8r"
   },
   "source": [
    "#DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1677833298544,
     "user": {
      "displayName": "Hanene Fatima Zohra BRACHEMI MEFTAH",
      "userId": "05471859942716114157"
     },
     "user_tz": -60
    },
    "id": "bpFKMh37BuFN"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import  DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1677833298545,
     "user": {
      "displayName": "Hanene Fatima Zohra BRACHEMI MEFTAH",
      "userId": "05471859942716114157"
     },
     "user_tz": -60
    },
    "id": "LcUWfgmZCYxB"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      2\u001b[0m train_dl \u001b[38;5;241m=\u001b[39m DataLoader(train_data, batch_size, shuffle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, pin_memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m val_dl \u001b[38;5;241m=\u001b[39m DataLoader(\u001b[43mval_data\u001b[49m, \u001b[38;5;241m1\u001b[39m, shuffle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_data' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "train_dl = DataLoader(train_data, batch_size, shuffle = True, pin_memory = True)\n",
    "val_dl = DataLoader(val_data, 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTLlBnsOCk11"
   },
   "source": [
    "#Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 12397,
     "status": "ok",
     "timestamp": 1677833352788,
     "user": {
      "displayName": "Hanene Fatima Zohra BRACHEMI MEFTAH",
      "userId": "05471859942716114157"
     },
     "user_tz": -60
    },
    "id": "4kdSHfnUCaN3"
   },
   "outputs": [],
   "source": [
    "from timesformer.models.vit import TimeSformer\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3911,
     "status": "ok",
     "timestamp": 1677833356687,
     "user": {
      "displayName": "Hanene Fatima Zohra BRACHEMI MEFTAH",
      "userId": "05471859942716114157"
     },
     "user_tz": -60
    },
    "id": "cHvvGK6nCcgj",
    "outputId": "4319f60f-15a9-4049-e6f5-77ff99fb8564"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretrained model URL is invalid, using random initialization.\n"
     ]
    }
   ],
   "source": [
    "model = TimeSformer(img_size=50,num_classes=1,patch_size=1,num_frames=20,attention_type='divided_space_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1677833356688,
     "user": {
      "displayName": "Hanene Fatima Zohra BRACHEMI MEFTAH",
      "userId": "05471859942716114157"
     },
     "user_tz": -60
    },
    "id": "ndm3PS5JfHTw",
    "outputId": "4af43858-a886-44ba-f7b4-986c61c779bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSformer(\n",
       "  (model): VisionTransformer(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv1d(2048, 768, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (time_drop): Dropout(p=0.0, inplace=False)\n",
       "    (blocks): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (head): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oY6UmNiMCmGJ"
   },
   "source": [
    "#Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1677833356688,
     "user": {
      "displayName": "Hanene Fatima Zohra BRACHEMI MEFTAH",
      "userId": "05471859942716114157"
     },
     "user_tz": -60
    },
    "id": "oto1I6FLCe3X"
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau \n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 807,
     "status": "ok",
     "timestamp": 1677833357490,
     "user": {
      "displayName": "Hanene Fatima Zohra BRACHEMI MEFTAH",
      "userId": "05471859942716114157"
     },
     "user_tz": -60
    },
    "id": "Yrkjj5O_Cnzj"
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders,criterion, optimizer,norm=100,debut=0, num_epochs=25, is_inception=False,scheduler=None):\n",
    "    since = time.time()\n",
    "\n",
    "    val_loss_history = []\n",
    "    loss_history = []\n",
    "    best_loss=99999999\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(debut,num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train']:\n",
    "            \n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for batch_idx, (inputs, labels) in tqdm(enumerate(dataloaders[phase])):\n",
    "                inputs = inputs.to(device, non_blocking=True)\n",
    "                labels = (labels.to(device))/norm\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    if is_inception and phase == 'train':\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        action_loss=loss\n",
    "                    preds = outputs\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        action_loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            loss_history.append(epoch_loss)\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(inputs), len(dataloaders[phase]),\n",
    "                100. * batch_idx / len(dataloaders[phase]), loss.item()))\n",
    "\n",
    "\n",
    "\n",
    "            print('{} Loss: {:.4f} '.format(phase, epoch_loss))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_loss_history.append(epoch_loss)\n",
    "            \n",
    "        scheduler.step(loss_history[-1])\n",
    "        torch.save(model.state_dict(), 'checkpoint.pth')\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "    vloss_history={}\n",
    "    vloss_history['val']=val_loss_history\n",
    "    vloss_history['loss']=loss_history\n",
    "   \n",
    "    return model, vloss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 3719,
     "status": "ok",
     "timestamp": 1677833361614,
     "user": {
      "displayName": "Hanene Fatima Zohra BRACHEMI MEFTAH",
      "userId": "05471859942716114157"
     },
     "user_tz": -60
    },
    "id": "3JvLHD8FCsqu"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSformer(\n",
       "  (model): VisionTransformer(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv1d(2048, 768, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (time_drop): Dropout(p=0.0, inplace=False)\n",
       "    (blocks): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (head): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8EoOFz-sCyek"
   },
   "source": [
    "#Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1677833361615,
     "user": {
      "displayName": "Hanene Fatima Zohra BRACHEMI MEFTAH",
      "userId": "05471859942716114157"
     },
     "user_tz": -60
    },
    "id": "8xvS-tT7Cvt1"
   },
   "outputs": [],
   "source": [
    "num_epochs =  30\n",
    "lr = 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1677833361616,
     "user": {
      "displayName": "Hanene Fatima Zohra BRACHEMI MEFTAH",
      "userId": "05471859942716114157"
     },
     "user_tz": -60
    },
    "id": "MgX4xRH0C35p"
   },
   "outputs": [],
   "source": [
    "model=model.float()\n",
    "params_to_update=[]\n",
    "for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            nn.init.normal_(param, mean=0.0, std=0.5)\n",
    "opt_func = torch.optim.Adam(params_to_update,lr=lr)\n",
    "scheduler = ReduceLROnPlateau(opt_func, 'min' ,patience=5,verbose=True)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8687,
     "status": "ok",
     "timestamp": 1677833370295,
     "user": {
      "displayName": "Hanene Fatima Zohra BRACHEMI MEFTAH",
      "userId": "05471859942716114157"
     },
     "user_tz": -60
    },
    "id": "503h3FmgU0rq",
    "outputId": "0a708a71-538a-4543-d01a-5d50f7a93dc6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('checkpoint2.pth',map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 394013,
     "status": "ok",
     "timestamp": 1677841532362,
     "user": {
      "displayName": "Hanene Fatima Zohra BRACHEMI MEFTAH",
      "userId": "05471859942716114157"
     },
     "user_tz": -60
    },
    "id": "LKBarXm_C6EV",
    "outputId": "4b2f38ae-8a27-49d6-9460-6372ee8b61cf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 8, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.75 GiB total capacity; 3.33 GiB already allocated; 17.00 MiB free; 3.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m [model,history] \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 48\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, criterion, optimizer, norm, debut, num_epochs, is_inception, scheduler)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     47\u001b[0m         action_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 48\u001b[0m         \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# statistics\u001b[39;00m\n\u001b[1;32m     51\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/hbrachem-venv/lib/python3.8/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/hbrachem-venv/lib/python3.8/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/hbrachem-venv/lib/python3.8/site-packages/torch/optim/adam.py:220\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    218\u001b[0m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexp_avg\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(p, memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mpreserve_format)\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# Exponential moving average of squared gradient values\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreserve_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamsgrad\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# Maintains max of all exp. moving avg. of sq. grad. values\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_exp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(p, memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mpreserve_format)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.75 GiB total capacity; 3.33 GiB already allocated; 17.00 MiB free; 3.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "[model,history] = train_model(model,dataloaders={'train':train_dl},optimizer=opt_func,num_epochs=num_epochs,\n",
    "                    criterion=criterion,scheduler=scheduler,norm=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "konvid.html  live.html  \u001b[0m\u001b[01;34mtrain\u001b[0m/  youtube.html\r\n"
     ]
    }
   ],
   "source": [
    "ls Features/resnet50/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "rQ438TkOT7MK"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1267,
     "status": "ok",
     "timestamp": 1677752932649,
     "user": {
      "displayName": "Hanene Fatima Zohra BRACHEMI MEFTAH",
      "userId": "05471859942716114157"
     },
     "user_tz": -60
    },
    "id": "0dcKfP6VT_ZC",
    "outputId": "99b450ac-d8b4-4a81-d150-9b08afd5d738"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " checkpoint.pth                   ids.pickle               \u001b[0m\u001b[01;34mtimesformer\u001b[0m/\n",
      "'CNN+TimeSformer (copie).ipynb'   __init__.py              tools.py\n",
      " CNN+TimeSformer.ipynb            \u001b[01;34m__MACOSX\u001b[0m/                \u001b[01;34mtrain\u001b[0m/\n",
      " data.ipynb                       \u001b[01;34m__pycache__\u001b[0m/             train_ids.pickle\n",
      " dataset.py                       scores1.pickle           train.txt\n",
      " \u001b[01;34mFeatures\u001b[0m/                        scores_combined.pickle   \u001b[01;34mvalidation\u001b[0m/\n",
      " features_extraction.ipynb        scores.pickle\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "wPNZjjMcihJl"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 693,
     "status": "ok",
     "timestamp": 1677752933339,
     "user": {
      "displayName": "Hanene Fatima Zohra BRACHEMI MEFTAH",
      "userId": "05471859942716114157"
     },
     "user_tz": -60
    },
    "id": "CgploFIailsx",
    "outputId": "492d3b83-cb07-419e-96d4-9983da467a32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efc223d12e0>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(range(len(history[\"val\"])),history[\"val\"])\n",
    "plt.plot(range(len(history[\"loss\"])),history[\"loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5N15-4fFOAg"
   },
   "source": [
    "#Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "iTcNHGrJJN7U"
   },
   "outputs": [],
   "source": [
    "def step(inputs):\n",
    "    data, label = inputs\n",
    "    data=data.cpu()\n",
    "    preds = model(data)\n",
    "    return preds, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.2451]),\n",
       " tensor([0.1448]),\n",
       " tensor([0.0917]),\n",
       " tensor([0.2222]),\n",
       " tensor([0.2305]),\n",
       " tensor([0.2109]),\n",
       " tensor([0.2140]),\n",
       " tensor([0.1596]),\n",
       " tensor([0.1953]),\n",
       " tensor([0.2343]),\n",
       " tensor([0.1065]),\n",
       " tensor([0.1246]),\n",
       " tensor([0.1892]),\n",
       " tensor([0.4091]),\n",
       " tensor([0.0026]),\n",
       " tensor([0.2116]),\n",
       " tensor([0.2157]),\n",
       " tensor([0.1410]),\n",
       " tensor([0.3507]),\n",
       " tensor([0.2074]),\n",
       " tensor([0.2502]),\n",
       " tensor([0.1876]),\n",
       " tensor([0.1423]),\n",
       " tensor([0.1908]),\n",
       " tensor([0.2854]),\n",
       " tensor([0.2317]),\n",
       " tensor([0.3812]),\n",
       " tensor([0.0831]),\n",
       " tensor([0.3462]),\n",
       " tensor([0.1765]),\n",
       " tensor([0.1388]),\n",
       " tensor([0.2153]),\n",
       " tensor([0.2004]),\n",
       " tensor([0.0653]),\n",
       " tensor([0.2272]),\n",
       " tensor([0.3639]),\n",
       " tensor([0.2161]),\n",
       " tensor([0.3916]),\n",
       " tensor([0.1990]),\n",
       " tensor([0.1929]),\n",
       " tensor([0.0366]),\n",
       " tensor([0.3829]),\n",
       " tensor([0.2358]),\n",
       " tensor([0.0363]),\n",
       " tensor([0.1828]),\n",
       " tensor([0.4003]),\n",
       " tensor([0.1381]),\n",
       " tensor([0.1682]),\n",
       " tensor([0.3658]),\n",
       " tensor([0.1962]),\n",
       " tensor([0.2248]),\n",
       " tensor([0.2479]),\n",
       " tensor([0.2632]),\n",
       " tensor([0.2175]),\n",
       " tensor([0.0480]),\n",
       " tensor([0.0641]),\n",
       " tensor([0.1521]),\n",
       " tensor([0.3381]),\n",
       " tensor([-0.0985]),\n",
       " tensor([0.0875]),\n",
       " tensor([0.2702]),\n",
       " tensor([0.2007]),\n",
       " tensor([0.2113]),\n",
       " tensor([0.3194]),\n",
       " tensor([0.1912]),\n",
       " tensor([0.3814]),\n",
       " tensor([0.1476]),\n",
       " tensor([0.2482]),\n",
       " tensor([0.2131]),\n",
       " tensor([0.2001]),\n",
       " tensor([0.2156]),\n",
       " tensor([0.2217]),\n",
       " tensor([0.0829]),\n",
       " tensor([0.1719]),\n",
       " tensor([0.3362]),\n",
       " tensor([0.1880]),\n",
       " tensor([0.1699]),\n",
       " tensor([0.2681]),\n",
       " tensor([0.4156]),\n",
       " tensor([0.1845]),\n",
       " tensor([0.1622]),\n",
       " tensor([0.4932]),\n",
       " tensor([0.0988]),\n",
       " tensor([0.2212]),\n",
       " tensor([0.2602]),\n",
       " tensor([0.3031]),\n",
       " tensor([0.2200]),\n",
       " tensor([0.4724]),\n",
       " tensor([0.0473]),\n",
       " tensor([0.3214]),\n",
       " tensor([0.2130]),\n",
       " tensor([0.3368]),\n",
       " tensor([0.2755]),\n",
       " tensor([0.2160]),\n",
       " tensor([0.2186]),\n",
       " tensor([0.2385]),\n",
       " tensor([0.0541]),\n",
       " tensor([0.2300]),\n",
       " tensor([0.1236]),\n",
       " tensor([0.2350]),\n",
       " tensor([0.3169]),\n",
       " tensor([0.2027]),\n",
       " tensor([0.2180]),\n",
       " tensor([0.3563]),\n",
       " tensor([0.2998]),\n",
       " tensor([0.1898]),\n",
       " tensor([0.2455]),\n",
       " tensor([0.1952]),\n",
       " tensor([0.2698]),\n",
       " tensor([0.2702]),\n",
       " tensor([0.1699]),\n",
       " tensor([0.0711]),\n",
       " tensor([0.2481]),\n",
       " tensor([0.1651]),\n",
       " tensor([0.2189]),\n",
       " tensor([0.4132]),\n",
       " tensor([0.0084]),\n",
       " tensor([0.0998]),\n",
       " tensor([0.2863]),\n",
       " tensor([0.1927]),\n",
       " tensor([0.1922]),\n",
       " tensor([0.2330]),\n",
       " tensor([0.2166]),\n",
       " tensor([0.2241]),\n",
       " tensor([0.1988]),\n",
       " tensor([0.1613]),\n",
       " tensor([0.2168]),\n",
       " tensor([0.0861]),\n",
       " tensor([0.2140]),\n",
       " tensor([0.2770]),\n",
       " tensor([0.2248]),\n",
       " tensor([0.0410]),\n",
       " tensor([0.2110]),\n",
       " tensor([0.1891]),\n",
       " tensor([0.2363]),\n",
       " tensor([-0.0499]),\n",
       " tensor([0.1590]),\n",
       " tensor([0.2747]),\n",
       " tensor([0.0649]),\n",
       " tensor([0.2663]),\n",
       " tensor([0.1881]),\n",
       " tensor([0.2381]),\n",
       " tensor([0.2209]),\n",
       " tensor([0.2184]),\n",
       " tensor([0.3697]),\n",
       " tensor([0.1610]),\n",
       " tensor([0.1813]),\n",
       " tensor([0.2224]),\n",
       " tensor([0.2039]),\n",
       " tensor([0.3849]),\n",
       " tensor([0.2313]),\n",
       " tensor([0.1720]),\n",
       " tensor([0.1922]),\n",
       " tensor([0.0449]),\n",
       " tensor([0.1862]),\n",
       " tensor([0.2488]),\n",
       " tensor([0.2039]),\n",
       " tensor([0.2705]),\n",
       " tensor([0.2034]),\n",
       " tensor([0.0129]),\n",
       " tensor([0.0739]),\n",
       " tensor([0.2045]),\n",
       " tensor([0.1015]),\n",
       " tensor([0.1815]),\n",
       " tensor([0.2311]),\n",
       " tensor([0.1227]),\n",
       " tensor([0.2221]),\n",
       " tensor([0.1390]),\n",
       " tensor([0.2403]),\n",
       " tensor([0.1190]),\n",
       " tensor([0.1958]),\n",
       " tensor([0.2604]),\n",
       " tensor([0.2228]),\n",
       " tensor([0.3771]),\n",
       " tensor([0.3882]),\n",
       " tensor([0.0262]),\n",
       " tensor([0.4136]),\n",
       " tensor([0.1944]),\n",
       " tensor([0.1227]),\n",
       " tensor([0.0499]),\n",
       " tensor([0.3009]),\n",
       " tensor([0.1614]),\n",
       " tensor([0.2446]),\n",
       " tensor([0.2610]),\n",
       " tensor([0.1474]),\n",
       " tensor([0.1148]),\n",
       " tensor([0.1227]),\n",
       " tensor([-0.0075]),\n",
       " tensor([0.1764]),\n",
       " tensor([0.1384]),\n",
       " tensor([0.2423]),\n",
       " tensor([0.3538]),\n",
       " tensor([0.1966]),\n",
       " tensor([0.0911]),\n",
       " tensor([0.4676]),\n",
       " tensor([0.1660]),\n",
       " tensor([0.1386]),\n",
       " tensor([0.2349]),\n",
       " tensor([0.3499]),\n",
       " tensor([-0.0827]),\n",
       " tensor([0.2985]),\n",
       " tensor([0.1628]),\n",
       " tensor([0.1969]),\n",
       " tensor([0.1972]),\n",
       " tensor([0.2109]),\n",
       " tensor([0.2622]),\n",
       " tensor([-0.0476]),\n",
       " tensor([0.0448]),\n",
       " tensor([0.1617]),\n",
       " tensor([0.1368]),\n",
       " tensor([-0.0597]),\n",
       " tensor([0.2362]),\n",
       " tensor([0.2673]),\n",
       " tensor([0.1885]),\n",
       " tensor([0.2586]),\n",
       " tensor([0.1977]),\n",
       " tensor([0.1596]),\n",
       " tensor([0.4892]),\n",
       " tensor([0.1872]),\n",
       " tensor([0.2721]),\n",
       " tensor([0.4251]),\n",
       " tensor([0.3706]),\n",
       " tensor([0.2322]),\n",
       " tensor([0.2211]),\n",
       " tensor([-0.0042]),\n",
       " tensor([0.1549]),\n",
       " tensor([-0.0537]),\n",
       " tensor([0.2104]),\n",
       " tensor([0.4146]),\n",
       " tensor([0.1972]),\n",
       " tensor([0.2640]),\n",
       " tensor([0.1910]),\n",
       " tensor([0.2730]),\n",
       " tensor([0.1478]),\n",
       " tensor([0.2047]),\n",
       " tensor([0.1991]),\n",
       " tensor([0.2185]),\n",
       " tensor([0.2461]),\n",
       " tensor([0.1731]),\n",
       " tensor([0.2316]),\n",
       " tensor([0.1700]),\n",
       " tensor([0.1825]),\n",
       " tensor([0.1124]),\n",
       " tensor([0.3314]),\n",
       " tensor([0.1404]),\n",
       " tensor([0.1760]),\n",
       " tensor([0.1307]),\n",
       " tensor([0.1619]),\n",
       " tensor([0.4254]),\n",
       " tensor([0.1678]),\n",
       " tensor([0.4348]),\n",
       " tensor([0.2266]),\n",
       " tensor([0.3609]),\n",
       " tensor([0.1908]),\n",
       " tensor([0.3883]),\n",
       " tensor([-0.0158]),\n",
       " tensor([0.2559]),\n",
       " tensor([0.3710]),\n",
       " tensor([0.2280]),\n",
       " tensor([0.2391]),\n",
       " tensor([0.2354]),\n",
       " tensor([0.1296]),\n",
       " tensor([0.2680]),\n",
       " tensor([0.1941]),\n",
       " tensor([0.3993]),\n",
       " tensor([0.2666]),\n",
       " tensor([0.1664]),\n",
       " tensor([0.1617]),\n",
       " tensor([0.0897]),\n",
       " tensor([0.3052]),\n",
       " tensor([0.0048]),\n",
       " tensor([0.2709]),\n",
       " tensor([0.2047]),\n",
       " tensor([0.1914]),\n",
       " tensor([0.2329]),\n",
       " tensor([0.2011]),\n",
       " tensor([0.2622]),\n",
       " tensor([-0.0181]),\n",
       " tensor([0.3661]),\n",
       " tensor([0.1761]),\n",
       " tensor([0.1685]),\n",
       " tensor([0.2052]),\n",
       " tensor([0.1760]),\n",
       " tensor([0.2474]),\n",
       " tensor([0.0399]),\n",
       " tensor([0.2580]),\n",
       " tensor([0.1699]),\n",
       " tensor([0.3916]),\n",
       " tensor([-0.0405]),\n",
       " tensor([0.2052]),\n",
       " tensor([0.2173]),\n",
       " tensor([0.2697]),\n",
       " tensor([0.0484]),\n",
       " tensor([0.3791]),\n",
       " tensor([0.2166]),\n",
       " tensor([0.2942]),\n",
       " tensor([0.2224]),\n",
       " tensor([0.0800]),\n",
       " tensor([0.4057]),\n",
       " tensor([0.2075]),\n",
       " tensor([-0.0100]),\n",
       " tensor([0.2560]),\n",
       " tensor([0.0729]),\n",
       " tensor([0.2546]),\n",
       " tensor([0.2652]),\n",
       " tensor([0.1200]),\n",
       " tensor([0.3963]),\n",
       " tensor([0.2526]),\n",
       " tensor([0.2973]),\n",
       " tensor([0.2429]),\n",
       " tensor([0.1850]),\n",
       " tensor([0.2667]),\n",
       " tensor([0.2253]),\n",
       " tensor([0.3020]),\n",
       " tensor([0.2634]),\n",
       " tensor([0.3650]),\n",
       " tensor([0.2478]),\n",
       " tensor([0.1334]),\n",
       " tensor([0.2407]),\n",
       " tensor([0.1403]),\n",
       " tensor([0.2257]),\n",
       " tensor([0.2211]),\n",
       " tensor([0.2276]),\n",
       " tensor([0.2779]),\n",
       " tensor([0.1068]),\n",
       " tensor([0.2069]),\n",
       " tensor([0.1773]),\n",
       " tensor([0.2022]),\n",
       " tensor([0.2088]),\n",
       " tensor([0.2220]),\n",
       " tensor([0.2437]),\n",
       " tensor([0.2081]),\n",
       " tensor([0.1634]),\n",
       " tensor([0.2055]),\n",
       " tensor([0.2097]),\n",
       " tensor([0.2936]),\n",
       " tensor([0.2618]),\n",
       " tensor([0.2285]),\n",
       " tensor([0.2771]),\n",
       " tensor([0.1966]),\n",
       " tensor([0.2897]),\n",
       " tensor([0.1788]),\n",
       " tensor([0.0940]),\n",
       " tensor([0.2120]),\n",
       " tensor([0.2942]),\n",
       " tensor([0.1374]),\n",
       " tensor([0.2073]),\n",
       " tensor([0.0746]),\n",
       " tensor([0.2391]),\n",
       " tensor([0.0542]),\n",
       " tensor([0.3333]),\n",
       " tensor([0.2077]),\n",
       " tensor([0.2084]),\n",
       " tensor([0.2171]),\n",
       " tensor([0.2312]),\n",
       " tensor([0.2205]),\n",
       " tensor([0.2816]),\n",
       " tensor([0.2036]),\n",
       " tensor([0.2311]),\n",
       " tensor([0.1693]),\n",
       " tensor([0.2007]),\n",
       " tensor([0.4242]),\n",
       " tensor([0.1147]),\n",
       " tensor([0.1551]),\n",
       " tensor([0.2582]),\n",
       " tensor([0.0691]),\n",
       " tensor([0.2156]),\n",
       " tensor([0.0021]),\n",
       " tensor([0.4312]),\n",
       " tensor([0.0858]),\n",
       " tensor([0.1688]),\n",
       " tensor([0.2214]),\n",
       " tensor([0.1457]),\n",
       " tensor([0.1642]),\n",
       " tensor([0.2848]),\n",
       " tensor([0.2506]),\n",
       " tensor([0.2260]),\n",
       " tensor([0.2216]),\n",
       " tensor([0.1637]),\n",
       " tensor([0.1377]),\n",
       " tensor([0.2055]),\n",
       " tensor([0.2789]),\n",
       " tensor([0.2053]),\n",
       " tensor([-0.3222]),\n",
       " tensor([0.2648]),\n",
       " tensor([0.3216]),\n",
       " tensor([0.1766]),\n",
       " tensor([0.2187]),\n",
       " tensor([0.2097]),\n",
       " tensor([0.1599]),\n",
       " tensor([0.2272]),\n",
       " tensor([0.1647]),\n",
       " tensor([0.2780]),\n",
       " tensor([0.1464]),\n",
       " tensor([0.2218]),\n",
       " tensor([0.2898]),\n",
       " tensor([-0.0150]),\n",
       " tensor([0.2001]),\n",
       " tensor([0.2158]),\n",
       " tensor([-0.0591]),\n",
       " tensor([0.1555]),\n",
       " tensor([0.3707]),\n",
       " tensor([0.1961]),\n",
       " tensor([0.0851]),\n",
       " tensor([0.1860]),\n",
       " tensor([0.2273]),\n",
       " tensor([0.1801]),\n",
       " tensor([0.2068]),\n",
       " tensor([0.2510]),\n",
       " tensor([-0.2336]),\n",
       " tensor([0.1100]),\n",
       " tensor([0.2732]),\n",
       " tensor([0.1878]),\n",
       " tensor([0.4141]),\n",
       " tensor([0.1864]),\n",
       " tensor([0.2343]),\n",
       " tensor([0.0381]),\n",
       " tensor([0.2827]),\n",
       " tensor([0.1960]),\n",
       " tensor([0.0065]),\n",
       " tensor([0.1260]),\n",
       " tensor([0.3011]),\n",
       " tensor([0.1980]),\n",
       " tensor([0.4151]),\n",
       " tensor([0.1505]),\n",
       " tensor([0.2383]),\n",
       " tensor([0.2608]),\n",
       " tensor([0.3425]),\n",
       " tensor([0.2664]),\n",
       " tensor([0.2390]),\n",
       " tensor([0.1909]),\n",
       " tensor([0.0902]),\n",
       " tensor([0.2552]),\n",
       " tensor([0.2249]),\n",
       " tensor([0.0422]),\n",
       " tensor([0.1636]),\n",
       " tensor([0.2168]),\n",
       " tensor([0.1907]),\n",
       " tensor([0.3422]),\n",
       " tensor([0.1727]),\n",
       " tensor([0.4242]),\n",
       " tensor([-0.0344]),\n",
       " tensor([0.1526]),\n",
       " tensor([0.3956]),\n",
       " tensor([0.1114]),\n",
       " tensor([0.2063]),\n",
       " tensor([0.1731]),\n",
       " tensor([0.4027]),\n",
       " tensor([0.2320]),\n",
       " tensor([0.2122]),\n",
       " tensor([0.1528]),\n",
       " tensor([0.3785]),\n",
       " tensor([0.2129]),\n",
       " tensor([0.0216]),\n",
       " tensor([0.1898]),\n",
       " tensor([0.2242]),\n",
       " tensor([0.2670]),\n",
       " tensor([0.3058]),\n",
       " tensor([0.0964]),\n",
       " tensor([0.1472]),\n",
       " tensor([0.1891]),\n",
       " tensor([0.1399]),\n",
       " tensor([0.1224]),\n",
       " tensor([0.2366]),\n",
       " tensor([0.2255]),\n",
       " tensor([0.0779]),\n",
       " tensor([0.1930]),\n",
       " tensor([0.1084]),\n",
       " tensor([0.0287]),\n",
       " tensor([0.1322]),\n",
       " tensor([0.1976]),\n",
       " tensor([0.2271]),\n",
       " tensor([0.0358]),\n",
       " tensor([0.0946]),\n",
       " tensor([0.2222]),\n",
       " tensor([0.2717]),\n",
       " tensor([0.2281]),\n",
       " tensor([0.0708]),\n",
       " tensor([0.2649]),\n",
       " tensor([0.1173]),\n",
       " tensor([0.1769]),\n",
       " tensor([0.2147]),\n",
       " tensor([0.2348]),\n",
       " tensor([-0.0118]),\n",
       " tensor([0.1474]),\n",
       " tensor([0.4029]),\n",
       " tensor([0.2016]),\n",
       " tensor([0.1622]),\n",
       " tensor([0.0610]),\n",
       " tensor([0.4491]),\n",
       " tensor([0.2406]),\n",
       " tensor([0.2233]),\n",
       " tensor([0.2378]),\n",
       " tensor([0.2505]),\n",
       " tensor([0.1020]),\n",
       " tensor([0.1860]),\n",
       " tensor([0.3889]),\n",
       " tensor([-0.0651]),\n",
       " tensor([0.0264]),\n",
       " tensor([0.1915]),\n",
       " tensor([0.3538]),\n",
       " tensor([-0.0152]),\n",
       " tensor([0.0535]),\n",
       " tensor([0.3169]),\n",
       " tensor([0.2334]),\n",
       " tensor([0.2661]),\n",
       " tensor([0.1551]),\n",
       " tensor([0.0463]),\n",
       " tensor([0.2200]),\n",
       " tensor([0.2599]),\n",
       " tensor([0.3874]),\n",
       " tensor([0.1855]),\n",
       " tensor([0.0754]),\n",
       " tensor([0.2020]),\n",
       " tensor([0.2481]),\n",
       " tensor([0.1877]),\n",
       " tensor([0.1733]),\n",
       " tensor([0.0437]),\n",
       " tensor([0.2261]),\n",
       " tensor([0.1687]),\n",
       " tensor([0.3137]),\n",
       " tensor([0.1585]),\n",
       " tensor([0.0516]),\n",
       " tensor([0.3439]),\n",
       " tensor([0.1854]),\n",
       " tensor([0.1979]),\n",
       " tensor([0.0616]),\n",
       " tensor([0.2196]),\n",
       " tensor([0.1802]),\n",
       " tensor([-0.0484]),\n",
       " tensor([0.0917]),\n",
       " tensor([0.0603]),\n",
       " tensor([0.2171]),\n",
       " tensor([0.2921]),\n",
       " tensor([0.1832]),\n",
       " tensor([0.2468]),\n",
       " tensor([0.1946]),\n",
       " tensor([0.2233]),\n",
       " tensor([0.2327]),\n",
       " tensor([-0.0045]),\n",
       " tensor([0.3054]),\n",
       " tensor([0.2680]),\n",
       " tensor([0.1462]),\n",
       " tensor([0.2309]),\n",
       " tensor([0.3830]),\n",
       " tensor([0.0472]),\n",
       " tensor([0.2577]),\n",
       " tensor([0.2418]),\n",
       " tensor([-0.0248]),\n",
       " tensor([0.2221]),\n",
       " tensor([0.1916]),\n",
       " tensor([0.1850]),\n",
       " tensor([0.2181]),\n",
       " tensor([0.1345]),\n",
       " tensor([-0.0154]),\n",
       " tensor([0.2139]),\n",
       " tensor([0.0424]),\n",
       " tensor([0.4107]),\n",
       " tensor([0.2526]),\n",
       " tensor([0.2887]),\n",
       " tensor([0.3428]),\n",
       " tensor([0.2442]),\n",
       " tensor([0.1694]),\n",
       " tensor([-0.3149]),\n",
       " tensor([-0.0819]),\n",
       " tensor([0.1941]),\n",
       " tensor([0.2410]),\n",
       " tensor([0.1975]),\n",
       " tensor([0.2319]),\n",
       " tensor([0.2346]),\n",
       " tensor([0.2215]),\n",
       " tensor([0.0370]),\n",
       " tensor([0.2301]),\n",
       " tensor([0.1764]),\n",
       " tensor([0.2134]),\n",
       " tensor([0.2193]),\n",
       " tensor([0.1981]),\n",
       " tensor([0.1544]),\n",
       " tensor([0.1968]),\n",
       " tensor([0.0376]),\n",
       " tensor([0.3963]),\n",
       " tensor([0.2600]),\n",
       " tensor([0.0619]),\n",
       " tensor([0.0886]),\n",
       " tensor([0.2998]),\n",
       " tensor([0.3565]),\n",
       " tensor([0.2317]),\n",
       " tensor([0.2069]),\n",
       " tensor([0.1446]),\n",
       " tensor([0.0945]),\n",
       " tensor([0.1700]),\n",
       " tensor([0.0150]),\n",
       " tensor([0.0913]),\n",
       " tensor([0.0402]),\n",
       " tensor([0.1650]),\n",
       " tensor([0.1236]),\n",
       " tensor([0.1600]),\n",
       " tensor([0.2611]),\n",
       " tensor([0.1193]),\n",
       " tensor([0.3462]),\n",
       " tensor([0.0528]),\n",
       " tensor([0.1467]),\n",
       " tensor([0.2110]),\n",
       " tensor([0.3058]),\n",
       " tensor([0.1066]),\n",
       " tensor([0.2528]),\n",
       " tensor([0.2901]),\n",
       " tensor([-0.2031]),\n",
       " tensor([0.0482]),\n",
       " tensor([0.2213]),\n",
       " tensor([-0.1959]),\n",
       " tensor([0.2273]),\n",
       " tensor([0.2192]),\n",
       " tensor([0.1644]),\n",
       " tensor([0.2844]),\n",
       " tensor([0.3861]),\n",
       " tensor([0.3976]),\n",
       " tensor([0.1167]),\n",
       " tensor([0.1761]),\n",
       " tensor([0.2553]),\n",
       " tensor([0.3909]),\n",
       " tensor([0.1888]),\n",
       " tensor([0.1896]),\n",
       " tensor([0.2600]),\n",
       " tensor([0.2138]),\n",
       " tensor([0.2284]),\n",
       " tensor([0.0881]),\n",
       " tensor([0.2280]),\n",
       " tensor([0.2530]),\n",
       " tensor([0.2960]),\n",
       " tensor([-0.0043]),\n",
       " tensor([0.3466]),\n",
       " tensor([0.2683]),\n",
       " tensor([-0.1812]),\n",
       " tensor([0.1904]),\n",
       " tensor([0.1977]),\n",
       " tensor([0.2541]),\n",
       " tensor([0.1086]),\n",
       " tensor([0.1216]),\n",
       " tensor([-0.2030]),\n",
       " tensor([0.2601]),\n",
       " tensor([0.2037]),\n",
       " tensor([0.2576]),\n",
       " tensor([-0.0937]),\n",
       " tensor([0.2090]),\n",
       " tensor([0.2340]),\n",
       " tensor([0.2377]),\n",
       " tensor([-0.1435]),\n",
       " tensor([0.2123]),\n",
       " tensor([0.1772]),\n",
       " tensor([0.2507]),\n",
       " tensor([0.0556]),\n",
       " tensor([0.3817]),\n",
       " tensor([0.3809]),\n",
       " tensor([0.2344]),\n",
       " tensor([0.3947]),\n",
       " tensor([0.1550]),\n",
       " tensor([0.2076]),\n",
       " tensor([0.1347]),\n",
       " tensor([0.2020]),\n",
       " tensor([0.1539]),\n",
       " tensor([0.2321]),\n",
       " tensor([0.2187]),\n",
       " tensor([0.2048]),\n",
       " tensor([0.2021]),\n",
       " tensor([-0.0422]),\n",
       " tensor([0.0317]),\n",
       " tensor([-0.0636]),\n",
       " tensor([0.1979]),\n",
       " tensor([0.1902]),\n",
       " tensor([0.2126]),\n",
       " tensor([0.2143]),\n",
       " tensor([0.2014]),\n",
       " tensor([0.2853]),\n",
       " tensor([-0.0596]),\n",
       " tensor([0.1453]),\n",
       " tensor([0.1426]),\n",
       " tensor([0.2431]),\n",
       " tensor([0.1996]),\n",
       " tensor([0.2638]),\n",
       " tensor([0.0722]),\n",
       " tensor([0.2616]),\n",
       " tensor([0.0729]),\n",
       " tensor([0.0834]),\n",
       " tensor([0.3853]),\n",
       " tensor([0.2102]),\n",
       " tensor([0.2242]),\n",
       " tensor([0.1254]),\n",
       " tensor([0.1826]),\n",
       " tensor([0.2632]),\n",
       " tensor([0.1751]),\n",
       " tensor([0.2565]),\n",
       " tensor([0.1223]),\n",
       " tensor([0.3793]),\n",
       " tensor([0.2083]),\n",
       " tensor([0.2908]),\n",
       " tensor([0.2267]),\n",
       " tensor([0.0858]),\n",
       " tensor([0.1710]),\n",
       " tensor([0.2801]),\n",
       " tensor([0.2457]),\n",
       " tensor([0.0370]),\n",
       " tensor([0.1387]),\n",
       " tensor([0.1887]),\n",
       " tensor([0.1551]),\n",
       " tensor([0.2534]),\n",
       " tensor([0.2162]),\n",
       " tensor([0.2562]),\n",
       " tensor([0.2504]),\n",
       " tensor([-0.0284]),\n",
       " tensor([-0.0466]),\n",
       " tensor([0.0203]),\n",
       " tensor([0.1746]),\n",
       " tensor([-0.0049]),\n",
       " tensor([0.2359]),\n",
       " tensor([0.2543]),\n",
       " tensor([0.2544]),\n",
       " tensor([0.2444]),\n",
       " tensor([0.2449]),\n",
       " tensor([0.2242]),\n",
       " tensor([0.0106]),\n",
       " tensor([-0.0375]),\n",
       " tensor([0.2561]),\n",
       " tensor([0.3182]),\n",
       " tensor([0.1740]),\n",
       " tensor([0.2515]),\n",
       " tensor([0.3169]),\n",
       " tensor([0.2784]),\n",
       " tensor([0.3881]),\n",
       " tensor([0.2441]),\n",
       " tensor([0.2644]),\n",
       " tensor([0.1829]),\n",
       " tensor([-0.0287]),\n",
       " tensor([0.1311]),\n",
       " tensor([-0.0793]),\n",
       " tensor([0.1422]),\n",
       " tensor([0.2471]),\n",
       " tensor([0.2452]),\n",
       " tensor([0.0630]),\n",
       " tensor([0.1711]),\n",
       " tensor([-0.0219]),\n",
       " tensor([-0.1776]),\n",
       " tensor([0.1982]),\n",
       " tensor([0.2267]),\n",
       " tensor([-0.0515]),\n",
       " tensor([-0.2231]),\n",
       " tensor([0.1253]),\n",
       " tensor([0.2332]),\n",
       " tensor([0.1685]),\n",
       " tensor([0.2529]),\n",
       " tensor([0.2194]),\n",
       " tensor([0.0103]),\n",
       " tensor([0.2789]),\n",
       " tensor([0.2682]),\n",
       " tensor([0.2318]),\n",
       " tensor([0.2429]),\n",
       " tensor([0.0926]),\n",
       " tensor([0.1731]),\n",
       " tensor([0.2335]),\n",
       " tensor([0.1541]),\n",
       " tensor([0.2283]),\n",
       " tensor([0.2218]),\n",
       " tensor([0.3563]),\n",
       " tensor([0.2629]),\n",
       " tensor([0.1851]),\n",
       " tensor([0.2097]),\n",
       " tensor([0.2032]),\n",
       " tensor([0.4194]),\n",
       " tensor([0.0950]),\n",
       " tensor([0.4029]),\n",
       " tensor([0.2682]),\n",
       " tensor([0.1958]),\n",
       " tensor([0.1521]),\n",
       " tensor([0.3504]),\n",
       " tensor([0.1669]),\n",
       " tensor([0.2406]),\n",
       " tensor([0.1942]),\n",
       " tensor([0.2521]),\n",
       " tensor([0.2169]),\n",
       " tensor([0.2678]),\n",
       " tensor([0.2373]),\n",
       " tensor([0.2250]),\n",
       " tensor([0.2419]),\n",
       " tensor([0.1881]),\n",
       " tensor([0.2042]),\n",
       " tensor([0.0469]),\n",
       " tensor([-0.0101]),\n",
       " tensor([0.1867]),\n",
       " tensor([0.2671]),\n",
       " tensor([0.2798]),\n",
       " tensor([0.1850]),\n",
       " tensor([0.2023]),\n",
       " tensor([0.1276]),\n",
       " tensor([0.1869]),\n",
       " tensor([0.2445]),\n",
       " tensor([0.0816]),\n",
       " tensor([0.2640]),\n",
       " tensor([0.1820]),\n",
       " tensor([0.2848]),\n",
       " tensor([0.1157]),\n",
       " tensor([0.2369]),\n",
       " tensor([0.2244]),\n",
       " tensor([0.1626]),\n",
       " tensor([0.3738]),\n",
       " tensor([0.2518]),\n",
       " tensor([0.2447]),\n",
       " tensor([0.2261]),\n",
       " tensor([0.2006]),\n",
       " tensor([-0.0019]),\n",
       " tensor([0.1563]),\n",
       " tensor([0.2564]),\n",
       " tensor([-0.1910]),\n",
       " tensor([0.1824]),\n",
       " tensor([0.2492]),\n",
       " tensor([0.1879]),\n",
       " tensor([0.1900]),\n",
       " tensor([0.1837]),\n",
       " tensor([0.1946]),\n",
       " tensor([0.2139]),\n",
       " tensor([0.2425]),\n",
       " tensor([0.2758]),\n",
       " tensor([0.0552]),\n",
       " tensor([0.2689]),\n",
       " tensor([0.2598]),\n",
       " tensor([0.0712]),\n",
       " tensor([0.2533]),\n",
       " tensor([0.1722]),\n",
       " tensor([0.1692]),\n",
       " tensor([0.2547]),\n",
       " tensor([0.0019]),\n",
       " tensor([0.2822]),\n",
       " tensor([0.2188]),\n",
       " tensor([0.2870]),\n",
       " tensor([0.3818]),\n",
       " tensor([0.2778]),\n",
       " tensor([0.2248]),\n",
       " tensor([0.2327]),\n",
       " tensor([0.2488]),\n",
       " tensor([0.1412]),\n",
       " tensor([0.2451]),\n",
       " tensor([0.1448]),\n",
       " tensor([0.0917]),\n",
       " tensor([0.2222]),\n",
       " tensor([0.2305]),\n",
       " tensor([0.2109]),\n",
       " tensor([0.2140]),\n",
       " tensor([0.1596]),\n",
       " tensor([0.1953]),\n",
       " tensor([0.2343]),\n",
       " tensor([0.1065]),\n",
       " tensor([0.1246]),\n",
       " tensor([0.1892]),\n",
       " tensor([0.4091]),\n",
       " tensor([0.0026]),\n",
       " tensor([0.2116]),\n",
       " tensor([0.2157]),\n",
       " tensor([0.1410]),\n",
       " tensor([0.3507]),\n",
       " tensor([0.2074]),\n",
       " tensor([0.2502]),\n",
       " tensor([0.1876]),\n",
       " tensor([0.1423]),\n",
       " tensor([0.1908]),\n",
       " tensor([0.2854]),\n",
       " tensor([0.2317]),\n",
       " tensor([0.3812]),\n",
       " tensor([0.0831]),\n",
       " tensor([0.3462]),\n",
       " tensor([0.1765]),\n",
       " tensor([0.1388]),\n",
       " tensor([0.2153]),\n",
       " tensor([0.2004]),\n",
       " tensor([0.0653]),\n",
       " tensor([0.2272]),\n",
       " tensor([0.3639]),\n",
       " tensor([0.2161]),\n",
       " tensor([0.3916]),\n",
       " tensor([0.1990]),\n",
       " tensor([0.1929]),\n",
       " tensor([0.0366]),\n",
       " tensor([0.3829]),\n",
       " tensor([0.2358]),\n",
       " tensor([0.0363]),\n",
       " tensor([0.1828]),\n",
       " tensor([0.4003]),\n",
       " tensor([0.1381]),\n",
       " tensor([0.1682]),\n",
       " tensor([0.3658]),\n",
       " tensor([0.1962]),\n",
       " tensor([0.2248]),\n",
       " tensor([0.2479]),\n",
       " tensor([0.2632]),\n",
       " tensor([0.2175]),\n",
       " tensor([0.0480]),\n",
       " tensor([0.0641]),\n",
       " tensor([0.1521]),\n",
       " tensor([0.3381]),\n",
       " tensor([-0.0985]),\n",
       " tensor([0.0875]),\n",
       " tensor([0.2702]),\n",
       " tensor([0.2007]),\n",
       " tensor([0.2113]),\n",
       " tensor([0.3194]),\n",
       " tensor([0.1912]),\n",
       " tensor([0.3814]),\n",
       " tensor([0.1476]),\n",
       " tensor([0.2482]),\n",
       " tensor([0.2131]),\n",
       " tensor([0.2001]),\n",
       " tensor([0.2156]),\n",
       " tensor([0.2217]),\n",
       " tensor([0.0829]),\n",
       " tensor([0.1719]),\n",
       " tensor([0.3362]),\n",
       " tensor([0.1880]),\n",
       " tensor([0.1699]),\n",
       " tensor([0.2681]),\n",
       " tensor([0.4156]),\n",
       " tensor([0.1845]),\n",
       " tensor([0.1622]),\n",
       " tensor([0.4932]),\n",
       " tensor([0.0988]),\n",
       " tensor([0.2212]),\n",
       " tensor([0.2602]),\n",
       " tensor([0.3031]),\n",
       " tensor([0.2200]),\n",
       " tensor([0.4724]),\n",
       " tensor([0.0473]),\n",
       " tensor([0.3214]),\n",
       " tensor([0.2130]),\n",
       " tensor([0.3368]),\n",
       " tensor([0.2755]),\n",
       " tensor([0.2160]),\n",
       " tensor([0.2186]),\n",
       " tensor([0.2385]),\n",
       " tensor([0.0541]),\n",
       " tensor([0.2300]),\n",
       " tensor([0.1236]),\n",
       " tensor([0.2350]),\n",
       " tensor([0.3169]),\n",
       " tensor([0.2027]),\n",
       " tensor([0.2180]),\n",
       " tensor([0.3563]),\n",
       " tensor([0.2998]),\n",
       " tensor([0.1898]),\n",
       " tensor([0.2455]),\n",
       " tensor([0.1952]),\n",
       " tensor([0.2698]),\n",
       " tensor([0.2702]),\n",
       " tensor([0.1699]),\n",
       " tensor([0.0711]),\n",
       " tensor([0.2481]),\n",
       " tensor([0.1651]),\n",
       " tensor([0.2189]),\n",
       " tensor([0.4132]),\n",
       " tensor([0.0084]),\n",
       " tensor([0.0998]),\n",
       " tensor([0.2863]),\n",
       " tensor([0.1927]),\n",
       " tensor([0.1922]),\n",
       " tensor([0.2330]),\n",
       " tensor([0.2166]),\n",
       " tensor([0.2241]),\n",
       " tensor([0.1988]),\n",
       " tensor([0.1613]),\n",
       " tensor([0.2168]),\n",
       " tensor([0.0861]),\n",
       " tensor([0.2140]),\n",
       " tensor([0.2770]),\n",
       " tensor([0.2248]),\n",
       " tensor([0.0410]),\n",
       " tensor([0.2110]),\n",
       " tensor([0.1891]),\n",
       " tensor([0.2363]),\n",
       " tensor([-0.0499]),\n",
       " tensor([0.1590]),\n",
       " tensor([0.2747]),\n",
       " tensor([0.0649]),\n",
       " tensor([0.2663]),\n",
       " tensor([0.1881]),\n",
       " tensor([0.2381]),\n",
       " tensor([0.2209]),\n",
       " tensor([0.2184]),\n",
       " tensor([0.3697]),\n",
       " tensor([0.1610]),\n",
       " tensor([0.1813]),\n",
       " tensor([0.2224]),\n",
       " tensor([0.2039]),\n",
       " tensor([0.3849]),\n",
       " tensor([0.2313]),\n",
       " tensor([0.1720]),\n",
       " tensor([0.1922]),\n",
       " tensor([0.0449]),\n",
       " tensor([0.1862]),\n",
       " tensor([0.2488]),\n",
       " tensor([0.2039]),\n",
       " tensor([0.2705]),\n",
       " tensor([0.2034]),\n",
       " tensor([0.0129]),\n",
       " tensor([0.0739]),\n",
       " ...]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1677752942853,
     "user": {
      "displayName": "Hanene Fatima Zohra BRACHEMI MEFTAH",
      "userId": "05471859942716114157"
     },
     "user_tz": -60
    },
    "id": "oikXCIxeDvWW",
    "outputId": "da8c3602-8e8c-41bb-b038-59f1cd7d0452"
   },
   "outputs": [],
   "source": [
    "val_dl = train_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 87571,
     "status": "ok",
     "timestamp": 1677753031235,
     "user": {
      "displayName": "Hanene Fatima Zohra BRACHEMI MEFTAH",
      "userId": "05471859942716114157"
     },
     "user_tz": -60
    },
    "id": "AJIhzvByFREw",
    "outputId": "dfdb847f-c146-4024-9086-5e4ec55ff285"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 839/839 [01:45<00:00,  7.94it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred=[]\n",
    "    label=[]\n",
    "    for i, batch in enumerate(tqdm(val_dl)):\n",
    "      \n",
    "     #  if id[0].split('/')[0] == 'train':\n",
    "          pred,l = step(batch)\n",
    "          y_pred.append(pred[0].cpu())\n",
    "          label.append(float(l[0][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "BQeVZI_sFR60"
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy.stats\n",
    "from concurrent import futures\n",
    "import functools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def logistic_func(X, bayta1, bayta2, bayta3, bayta4):\n",
    "  # 4-parameter logistic function\n",
    "  logisticPart = 1 + np.exp(np.negative(np.divide(X - bayta3, np.abs(bayta4))))\n",
    "  yhat = bayta2 + np.divide(bayta1 - bayta2, logisticPart)\n",
    "  return yhat\n",
    "\n",
    "def compute_metrics(y_pred, y):\n",
    "  '''\n",
    "  compute metrics btw predictions & labels\n",
    "  '''\n",
    "  # compute SRCC & KRCC\n",
    "  SRCC = scipy.stats.spearmanr(y, y_pred)[0]\n",
    "  try:\n",
    "    KRCC = scipy.stats.kendalltau(y, y_pred)[0]\n",
    "  except:\n",
    "    KRCC = scipy.stats.kendalltau(y, y_pred, method='asymptotic')[0]\n",
    "\n",
    "  # logistic regression btw y_pred & y\n",
    "  beta_init = [np.max(y), np.min(y), np.mean(y_pred), 0.5]\n",
    "  popt, _ = curve_fit(logistic_func, y_pred, y, p0=beta_init, maxfev=int(1e8))\n",
    "  y_pred_logistic = logistic_func(y_pred, *popt)\n",
    "  \n",
    "  # compute  PLCC RMSE\n",
    "  PLCC = scipy.stats.pearsonr(y, y_pred_logistic)[0]\n",
    "  RMSE = np.sqrt(mean_squared_error(y, y_pred_logistic))\n",
    "  return [SRCC, KRCC, PLCC, RMSE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XaXp-Ho2FUGu"
   },
   "source": [
    "#Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1677753033383,
     "user": {
      "displayName": "Hanene Fatima Zohra BRACHEMI MEFTAH",
      "userId": "05471859942716114157"
     },
     "user_tz": -60
    },
    "id": "yy6OYhqrFPeC",
    "outputId": "796978d7-7f15-4ad3-c312-033486b65a64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2305])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1677678517946,
     "user": {
      "displayName": "Brachemi Hanene",
      "userId": "13579458267954467461"
     },
     "user_tz": -60
    },
    "id": "qBXRgg_PFNcv",
    "outputId": "96c19501-b109-4379-a3cb-274723c77a4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67.82231140136719"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "-FgWU94vFTfh"
   },
   "outputs": [],
   "source": [
    "y=[]\n",
    "for i in range(len(y_pred)):\n",
    "  y.append(y_pred[i].cpu()[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "gHqDtMRUFXAw"
   },
   "outputs": [],
   "source": [
    "y_true=label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "Za4cnk6UFZC-"
   },
   "outputs": [],
   "source": [
    "[SRCC, KRCC, PLCC, RMSE]=compute_metrics(y,y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1677753033927,
     "user": {
      "displayName": "Hanene Fatima Zohra BRACHEMI MEFTAH",
      "userId": "05471859942716114157"
     },
     "user_tz": -60
    },
    "id": "l8cbR-0aFagx",
    "outputId": "030094f0-e49b-414b-ecae-cc194ba86b0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.032282964758835284"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1677753033928,
     "user": {
      "displayName": "Hanene Fatima Zohra BRACHEMI MEFTAH",
      "userId": "05471859942716114157"
     },
     "user_tz": -60
    },
    "id": "hZZUMKPiJkMt",
    "outputId": "4c8621be-7c8b-4096-ce7e-295cd492fbcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06790882407019916"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PLCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 407,
     "status": "ok",
     "timestamp": 1677753071499,
     "user": {
      "displayName": "Hanene Fatima Zohra BRACHEMI MEFTAH",
      "userId": "05471859942716114157"
     },
     "user_tz": -60
    },
    "id": "r4yDdNfqJktk",
    "outputId": "efe16bb4-403d-4e29-f610-1548f200367a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02148540284063594"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KRCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677753074448,
     "user": {
      "displayName": "Hanene Fatima Zohra BRACHEMI MEFTAH",
      "userId": "05471859942716114157"
     },
     "user_tz": -60
    },
    "id": "LaRIdEnoT7xB",
    "outputId": "58a7dadb-7925-42e4-8047-be4139959e9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.906629867092361"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0uc6EGWMTf1U"
   },
   "outputs": [],
   "source": [
    "def load_my_state_dict(model, state_dict,exceptions):\n",
    " \n",
    "        own_state = model.state_dict()\n",
    "        for name, param in state_dict.items():\n",
    "          try:\n",
    "            param = param.data\n",
    "            own_state[name].copy_(param)\n",
    "          except:\n",
    "            print('layer not copied: '+name)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bx5jOYk1UhMA",
    "outputId": "6699afe7-5cd0-40e7-ce9e-c77856fc3b87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_resnet50.pth\r\n"
     ]
    }
   ],
   "source": [
    "ls *.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bHYhlFgKUhMA"
   },
   "outputs": [],
   "source": [
    "s=torch.load(\"./combined_resnet50.pth\",map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3JQNipLbUhMA"
   },
   "outputs": [],
   "source": [
    "load_my_state_dict(model,s,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-EykEoojUhMB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
