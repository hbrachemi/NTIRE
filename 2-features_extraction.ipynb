{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eZmOnISNxR9p"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "We6KfkOPOGnr"
   },
   "source": [
    "PLEASE MAKE SURE TO EDIT THE PATHS TO THE DATASETS AND THE PARAMETERS SUCH AS THE CNN BACKBONE 'base' ACCORDING TO YOUR CASE SCENARIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZfRCU8gvQxjG"
   },
   "outputs": [],
   "source": [
    "#Global variables\n",
    "params = {'base':'resnet',    \n",
    "        'dim':(224,224), #dim of extracted patches\n",
    "        \n",
    "        'db_path':'./test/', #path to videos \n",
    "        \n",
    "        'num_frames':8, #idealy we want to keep one frame per second\n",
    "        \n",
    "        'num_patches':1 #least number of patches to be extracted from the frame, if the actual number is less than \n",
    "          #'num_patches', overlapping will be used in order to achieve this parametter\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XnanGxMVQ3FH"
   },
   "outputs": [],
   "source": [
    "list_IDs_path='./ids_test.pickle' \n",
    "\n",
    "pickle_in = open(list_IDs_path,'rb')\n",
    "ids= pickle.load(pickle_in)\n",
    "pickle_in.close()\n",
    "\n",
    "out = 'Features/resnet50/test' #path toward forder where features will be saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asEyDIuziMLf"
   },
   "source": [
    "#CNN backbone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RsyhJj1aiXwi"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g_LI6undhDHR"
   },
   "outputs": [],
   "source": [
    "def Base_Model(base,weights='imagenet', include_top=False, input_shape=(299, 299, 3)):\n",
    "    if(base=='resnet50'):\n",
    "        return ResNet50(weights=weights, include_top=include_top, input_shape=input_shape)\n",
    "    if(base=='vgg16'):\n",
    "        return VGG16(weights=weights, include_top=include_top, input_shape=input_shape)\n",
    "    if(base=='vgg19'):\n",
    "        return VGG19(weights=weights, include_top=include_top, input_shape=input_shape)\n",
    "    if(base=='densenet121'):\n",
    "        return DenseNet121(weights=weights, include_top=include_top, input_shape=input_shape)\n",
    "    if(base=='inceptionv3'):\n",
    "        return InceptionV3(weights=weights, include_top=include_top, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJKirED9iavd"
   },
   "source": [
    "#Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ax5wqLnvjT-f"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pickle\n",
    "import slidingwindow as sw\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-FJRec3NUCqI"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "error",
     "timestamp": 1677743435832,
     "user": {
      "displayName": "Hanene Fatima Zohra BRACHEMI MEFTAH",
      "userId": "05471859942716114157"
     },
     "user_tz": -60
    },
    "id": "SGKi7pCeuvHy",
    "outputId": "946c2bf3-1505-4657-95d6-8f5434196c89"
   },
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self,dim=(224,224),n_channels=3,n_output=1,base='resnet',\n",
    "                db_path='KoNViD_1k_videos/',threshold=0.5,\n",
    "                ids=[],num_frames=8,num_patches=6,max_p=30):\n",
    "        'Initialization'\n",
    "        self.max_p=max_p\n",
    "        self.num_patches=num_patches\n",
    "        self.num_frames=num_frames\n",
    "        self.batch_size= 1\n",
    "        self.dim = dim\n",
    "        self.n_channels = n_channels\n",
    "        self.n_output = n_output\n",
    "        self.base=base\n",
    "        self.db_path=db_path\n",
    "        self.ids_path=ids\n",
    "        self.list_IDs_temp=[]\n",
    "        self.list_IDs=ids\n",
    "        self.threshold=threshold\n",
    "                \n",
    "\n",
    "        vidcap = cv2.VideoCapture(os.path.join(self.db_path,id))\n",
    "        self.N = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        self.fps = int(vidcap.get(cv2.CAP_PROP_FPS))\n",
    "        \n",
    "        success,image = vidcap.read()\n",
    "        ov = 0\n",
    "        windows = sw.generate(image, sw.DimOrder.HeightWidthChannel,self.dim[0],ov)\n",
    "        \n",
    "        while len(windows) < self.num_patches:\n",
    "            ov =ov+ 0.1\n",
    "            windows = sw.generate(image, sw.DimOrder.HeightWidthChannel,self.dim[0],ov)\n",
    "            if ov > self.threshold:\n",
    "              break;\n",
    "        self.ov=ov\n",
    "\n",
    "        if len(windows) > max_p:\n",
    "          self.p=max_p\n",
    "        else:\n",
    "          self.p= len(windows)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs)/ self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # Find list of IDs\n",
    "        self.list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        # Generate data\n",
    "        X = self.__data_generation(self.list_IDs_temp)\n",
    "        return X\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        \n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "      for i, ID in enumerate(list_IDs_temp):\n",
    "        n=self.dim[0]\n",
    "    \n",
    "        images=[]\n",
    "        vidcap = cv2.VideoCapture(os.path.join(self.db_path,ID))\n",
    "        success,image = vidcap.read()\n",
    "       \n",
    "       \n",
    "       \n",
    "       \n",
    "        count = 0;\n",
    "        while success:\n",
    "          if count % self.fps ==0:\n",
    "            images.append(cv2.cvtColor(image,cv2.COLOR_BGR2RGB))\n",
    "          count += 1\n",
    "          if (count+1) == self.num_frames:\n",
    "            images.append(cv2.cvtColor(image,cv2.COLOR_BGR2RGB))\n",
    "          success,image = vidcap.read()\n",
    "       \n",
    "        \n",
    "\n",
    "        X = np.empty((self.num_frames,self.p,*self.dim, self.n_channels))\n",
    "            \n",
    "        for k in range(self.num_frames):\n",
    "\n",
    "            image=images[k]\n",
    "\n",
    "            windows = sw.generate(image, sw.DimOrder.HeightWidthChannel,n,self.ov)\n",
    "                \n",
    "            for l in range(self.p):  \n",
    "                \n",
    "                if self.p < self.max_p:    \n",
    "                    subset = image[windows[l].indices()]\n",
    "                else:\n",
    "                    subset=image[windows[int(len(windows)/self.p*l)].indices()]\n",
    "                    \n",
    "                if self.base=='vgg16':\n",
    "                      subset=keras.applications.vgg16.preprocess_input(subset)\n",
    "                elif self.base=='inceptionv3':\n",
    "                      subset=keras.applications.inception_v3.preprocess_input(subset)\n",
    "                elif self.base=='resnet':\n",
    "                      subset=keras.applications.resnet.preprocess_input(subset)\n",
    "                elif self.base=='densenet121':\n",
    "                      subset=keras.applications.densenet.preprocess_input(subset)\n",
    "                else:\n",
    "                      print(\"No preprocessing..\")\n",
    "                X[k,l,:,:,:] =np.array(subset) \n",
    "\n",
    "                             \n",
    "      return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hurLwcqgmIiO"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import MaxPooling2D,Input,GlobalMaxPooling2D,GlobalAveragePooling2D,AveragePooling2D\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5906,
     "status": "ok",
     "timestamp": 1676989960430,
     "user": {
      "displayName": "Hanene Fatima Zohra BRACHEMI MEFTAH",
      "userId": "05471859942716114157"
     },
     "user_tz": -60
    },
    "id": "7CxdyZ9ml-IE",
    "outputId": "a6723535-c8f4-4a9e-f4a9-2e490b8674ed"
   },
   "outputs": [],
   "source": [
    "#Model definition\n",
    "\n",
    "base_model =  Base_Model('resnet50',weights='imagenet', include_top=False, input_shape=(224,224, 3))\n",
    "\n",
    "x=base_model.layers[-1].output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "model=keras.Model(inputs=base_model.layers[0].output,outputs=x)\n",
    "\n",
    "input=Input(shape=(None,224,224,3))\n",
    "output= layers.TimeDistributed(model)(input)\n",
    "model_cnn=keras.Model(inputs=input,outputs=output)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1962570,
     "status": "ok",
     "timestamp": 1676993568984,
     "user": {
      "displayName": "Hanene Fatima Zohra BRACHEMI MEFTAH",
      "userId": "05471859942716114157"
     },
     "user_tz": -60
    },
    "id": "KaRrrJncnxrh",
    "outputId": "864c7ee4-11d0-4e42-c594-bb6e14b09b4c"
   },
   "outputs": [],
   "source": [
    "t=[]\n",
    "for id in ids:\n",
    "        t1 = time.time()\n",
    "        generator = DataGenerator(ids=[id],**params)\n",
    "        feature= model_cnn.predict_generator(generator=generator)\n",
    "        t2 = time.time()\n",
    "        t.append(t2-t1)\n",
    "        np.save(os.path.join(out,id+'.npy'),feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8cN5VnykrWm"
   },
   "outputs": [],
   "source": [
    "np.mean(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J36GJYwiXfs8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
